{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "데이터셋합치기.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 과정\n",
        "1. 교차로 dataset 를 yolo txt 형식에 맞게 변환 \n",
        "(Zebra_cross : 0,G_Signal : 1,R_Signal : 2 ) \n",
        "    => 왜 ? 이것도 나중에 개별 데이터셋으로 활용하기 위해 (1회성 데이터셋이 아닌 나중에도 써먹기 위해)\n",
        "\n",
        "2. 변환된 파일을 zip파일로 저장\n",
        "\n",
        "3. 변환된 파일과 버스 데이터를 합치는데   \n",
        "버스 데이터와 교차로 데이터의 인덱스를 맞춰야됨\n",
        "\n",
        "4. 그냥.. 원본 데이터셋에서 변형된 버전을 하나 만들기로함...\n",
        "\n",
        "5. 그러고 버스랑 합친 MergedDataset 파일 만들고 그거 zip 묶어서 저장~"
      ],
      "metadata": {
        "id": "Pe1k8QtN7ANb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "96FnndntkQdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "73616개"
      ],
      "metadata": {
        "id": "Z6ey-O_pdtn3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross 데이터셋 변형 1 (0, 1, 2)"
      ],
      "metadata": {
        "id": "7u1FhnjSsUxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from os import walk, getcwd\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from glob import glob\n",
        "\n",
        "import yaml\n",
        "import json\n",
        "\n",
        "from IPython.display import Image\n",
        "\n",
        "from pathlib import Path\n",
        "import cv2"
      ],
      "metadata": {
        "id": "4vILj1CdUD4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Unzip Image File\n",
        "%cd /content\n",
        "!unzip -qq \"/content/gdrive/MyDrive/Colab Notebooks/YOLO V5/cross.zip\" ## Folder 6개가 생김\n",
        "print('Complete!')"
      ],
      "metadata": {
        "id": "1YsrKjaCO-qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "압축이 해제된 폴더들은 Object의 수에 따라 1~6으로 구분 해둔 것임\n",
        "따라서 일단 안의 파일들을 다 하나로 합쳐준 다음 Train Val 분리를 해주기로 결정\n",
        "'''\n",
        "\n",
        "os.makedirs('./dataset') ## 1~6으로 분할 되어있는 파일을 다 모아줄 폴더 생성\n",
        "\n",
        "to_here = '/content/dataset'\n",
        "\n",
        "\n",
        "for i in tqdm(range(1,7)) :\n",
        "    get_file = os.listdir(f'/content/교차로정보 데이터셋_bbox_{i}') ## 폴더 내의 파일들 리스트로 묶음\n",
        "    for j in get_file :\n",
        "        shutil.move(f'/content/교차로정보 데이터셋_bbox_{i}/'+j, to_here) ## dataset 폴더로 모두 이동\n",
        "    os.rmdir(f'/content/교차로정보 데이터셋_bbox_{i}') "
      ],
      "metadata": {
        "id": "wFiuSWc4ONcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## json Label Data를 이제 txt로 바꿔줘야됨 (이게 제일 빡... ㅠ)\n",
        "## class | x_center | y_center | width | height 순서임\n",
        "\n",
        "## Train Data 변환 ##\n",
        "mypath = \"/content/dataset/\"\n",
        "\n",
        "os.makedirs('/content/yolo_texts') \n",
        "outputpath = '/content/yolo_texts/'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def convert(size, box):\n",
        "    dw = 1. / (size[0])\n",
        "    dh = 1. / (size[1])\n",
        "    x = (box[0] + box[1]) / 2.0 - 1\n",
        "    y = (box[2] + box[3]) / 2.0 - 1\n",
        "    w = box[1] - box[0]\n",
        "    h = box[3] - box[2]\n",
        "    x = x * dw\n",
        "    w = w * dw\n",
        "    y = y * dh\n",
        "    h = h * dh\n",
        "    return (x, y, w, h)\n",
        "\n",
        "json_name_list = []\n",
        "for file in os.listdir(mypath):\n",
        "    if file.endswith(\".json\"):\n",
        "        json_name_list.append(file)\n",
        "\n",
        "## Class 정의\n",
        "obj_classes = ['Zebra_Cross','G_Signal','R_Signal']\n",
        "\n",
        "\n",
        "for json_file in tqdm(json_name_list) : \n",
        "\n",
        "    ## txt 파일로 바꿔줄 이름 !\n",
        "    txt_file_path = outputpath+json_file.split('.')[0] + '.txt'\n",
        "    txt_label = open(txt_file_path, 'w') ## 이 파일에다가 쓸 거야!\n",
        "\n",
        "    json_obj = json.load(open(mypath+json_file, 'r', encoding='utf-8'))  ## json 파일 오픈\n",
        "    height = json_obj['imageHeight'] ## image에서 i 대문자 아니고 소문자임 ㅋㅋㅋ ㅠㅠㅠㅠㅠ\n",
        "    width = json_obj['imageWidth'] ## 이미지의 높이 정보, 너비정보\n",
        "    for idx, i in enumerate(json_obj['shapes']) : \n",
        "        label = i['label']\n",
        "        if label == '1' : ## 중간에 라벨에 1이라고 잘못한 게 있는듯 그거 패스해버림\n",
        "            continue\n",
        "        points = i['points']\n",
        "        if (i[\"shape_type\"] == 'rectangle'):\n",
        "            points = np.array(i[\"points\"])\n",
        "            xmin = min(points[:, 0]) if min(points[:, 0]) > 0 else 0\n",
        "            xmax = max(points[:, 0]) if max(points[:, 0]) > 0 else 0\n",
        "            ymin = min(points[:, 1]) if min(points[:, 1]) > 0 else 0\n",
        "            ymax = max(points[:, 1]) if max(points[:, 1]) > 0 else 0\n",
        "\n",
        "            ## 이상한 거 없나 체크\n",
        "            if xmax <= xmin:\n",
        "                pass\n",
        "            elif ymax <= ymin:\n",
        "                pass\n",
        "            else:\n",
        "                ## 이상 없으면 변환시킴\n",
        "                bbox_labelme_float   = (float(xmin), float(xmax), float(ymin), float(ymax))\n",
        "                bbox_yolo_normalized = convert((width, height), bbox_labelme_float)\n",
        "\n",
        "                ## class_id는 obj_classes에 맞는 index가 됨\n",
        "                ## 횡단보도 = 0 , 초록불 = 1 , 빨간불 =2            \n",
        "                class_id = obj_classes.index(label)\n",
        "\n",
        "                ## 드디어~~ txt 파일로 작성!!!!! (한줄)\n",
        "                txt_label.write(str(class_id)+ ' ' + ' '.join([str(a) for a in bbox_yolo_normalized])+'\\n')\n",
        "\n",
        "    ## 다 썼으면 닫기\n",
        "    txt_label.close()"
      ],
      "metadata": {
        "id": "wGWuTNsgONe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_lst = []\n",
        "\n",
        "get_file = os.listdir(f'/content/dataset') ## 폴더 내의 파일들 리스트로 묶음\n",
        "for j in get_file :\n",
        "    if j.endswith('.png') : \n",
        "        img_lst.append(j)\n",
        "    if j.endswith('.jpg') : \n",
        "        img_lst.append(j)"
      ],
      "metadata": {
        "id": "e6L4TIKoONjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil \n",
        "import tqdm\n",
        "\n",
        "for img in tqdm(img_lst) : \n",
        "    shutil.move(f'/content/dataset/{img}', '/content/yolo_texts')"
      ],
      "metadata": {
        "id": "sQ5co7qAONlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(glob('/content/yolo_texts/*'))"
      ],
      "metadata": {
        "id": "YgyM2Kk4ONnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "YOLO Texts로 변환시킨 데이터셋만 zip일단 시킴(안전빵)"
      ],
      "metadata": {
        "id": "mka7v2ussEcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/yolo_texts.zip /content/yolo_texts"
      ],
      "metadata": {
        "id": "mj96lvugONpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('이미지 수 \\n',\n",
        "      len(glob('/content/yolo_texts/*.png')) + len(list(glob('/content/yolo_texts/*.jpg'))))\n",
        "print('txt로 변환한 라벨 수 \\n',\n",
        "      len(glob('/content/yolo_texts/*.txt')))\n",
        "\n",
        "print('총 파일 수 : {이전과 일치, 모든 파일 정상 변환 완료}\\n',\n",
        "      len(glob('/content/yolo_texts/*')))\n"
      ],
      "metadata": {
        "id": "bgWfRlHHONrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "일단 다운로드"
      ],
      "metadata": {
        "id": "lK-vzJKEsA8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/yolo_texts.zip')"
      ],
      "metadata": {
        "id": "JDuzHRs7f_ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross 변형 2 (12, 13, 14)"
      ],
      "metadata": {
        "id": "YqKCKs_4_oyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Unzip Image File\n",
        "%cd /content\n",
        "!unzip -qq \"/content/gdrive/MyDrive/Colab Notebooks/YOLO_V5/cross.zip\" ## Folder 6개가 생김\n",
        "print('Complete!')"
      ],
      "metadata": {
        "id": "xl5kkAelALlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "import shutil\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "os.makedirs('./dataset') ## 1~6으로 분할 되어있는 파일을 다 모아줄 폴더 생성\n",
        "\n",
        "to_here = '/content/dataset'\n",
        "\n",
        "\n",
        "for i in tqdm(range(1,7)) :\n",
        "    get_file = os.listdir(f'/content/교차로정보 데이터셋_bbox_{i}') ## 폴더 내의 파일들 리스트로 묶음\n",
        "    for j in get_file :\n",
        "        shutil.move(f'/content/교차로정보 데이터셋_bbox_{i}/'+j, to_here) ## dataset 폴더로 모두 이동\n",
        "    os.rmdir(f'/content/교차로정보 데이터셋_bbox_{i}') "
      ],
      "metadata": {
        "id": "ugSQ6bOMALlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "\n",
        "mypath = \"/content/dataset/\"\n",
        "\n",
        "os.makedirs('/content/ProjectVerCross') \n",
        "outputpath = '/content/ProjectVerCross/'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def convert(size, box):\n",
        "    dw = 1. / (size[0])\n",
        "    dh = 1. / (size[1])\n",
        "    x = (box[0] + box[1]) / 2.0 - 1\n",
        "    y = (box[2] + box[3]) / 2.0 - 1\n",
        "    w = box[1] - box[0]\n",
        "    h = box[3] - box[2]\n",
        "    x = x * dw\n",
        "    w = w * dw\n",
        "    y = y * dh\n",
        "    h = h * dh\n",
        "    return (x, y, w, h)\n",
        "\n",
        "json_name_list = []\n",
        "for file in os.listdir(mypath):\n",
        "    if file.endswith(\".json\"):\n",
        "        json_name_list.append(file)\n",
        "\n",
        "## Class 정의\n",
        "obj_classes = ['Zebra_Cross','G_Signal','R_Signal']\n",
        "\n",
        "\n",
        "for json_file in tqdm(json_name_list) : \n",
        "\n",
        "    ## txt 파일로 바꿔줄 이름 !\n",
        "    txt_file_path = outputpath+json_file.split('.')[0] + '.txt'\n",
        "    txt_label = open(txt_file_path, 'w') ## 이 파일에다가 쓸 거야!\n",
        "\n",
        "    json_obj = json.load(open(mypath+json_file, 'r', encoding='utf-8'))  ## json 파일 오픈\n",
        "    height = json_obj['imageHeight'] ## image에서 i 대문자 아니고 소문자임 ㅋㅋㅋ ㅠㅠㅠㅠㅠ\n",
        "    width = json_obj['imageWidth'] ## 이미지의 높이 정보, 너비정보\n",
        "    for idx, i in enumerate(json_obj['shapes']) : \n",
        "        label = i['label']\n",
        "        if label == '1' : ## 중간에 라벨에 1이라고 잘못한 게 있는듯 그거 패스해버림\n",
        "            continue\n",
        "        points = i['points']\n",
        "        if (i[\"shape_type\"] == 'rectangle'):\n",
        "            points = np.array(i[\"points\"])\n",
        "            xmin = min(points[:, 0]) if min(points[:, 0]) > 0 else 0\n",
        "            xmax = max(points[:, 0]) if max(points[:, 0]) > 0 else 0\n",
        "            ymin = min(points[:, 1]) if min(points[:, 1]) > 0 else 0\n",
        "            ymax = max(points[:, 1]) if max(points[:, 1]) > 0 else 0\n",
        "\n",
        "            ## 이상한 거 없나 체크\n",
        "            if xmax <= xmin:\n",
        "                pass\n",
        "            elif ymax <= ymin:\n",
        "                pass\n",
        "            else:\n",
        "                ## 이상 없으면 변환시킴\n",
        "                bbox_labelme_float   = (float(xmin), float(xmax), float(ymin), float(ymax))\n",
        "                bbox_yolo_normalized = convert((width, height), bbox_labelme_float)\n",
        "\n",
        "                '''\n",
        "                이 부분을 수정함.\n",
        "                기존의 횡단보도, 신호등 이미지들을 12 13 14 으로\n",
        "                '''\n",
        "\n",
        "                if obj_classes.index(label) == 0 :\n",
        "                    class_id = 12 ## Zebra_Cross : 12\n",
        "                elif obj_classes.index(label) == 1 :\n",
        "                    class_id = 13 ## G_Signal : 13\n",
        "                elif obj_classes.index(label) == 2 :\n",
        "                    class_id = 14 ## R_Signal : 14\n",
        "\n",
        "                ## 드디어~~ txt 파일로 작성!!!!! (한줄)\n",
        "                txt_label.write(str(class_id)+ ' ' + ' '.join([str(a) for a in bbox_yolo_normalized])+'\\n')\n",
        "\n",
        "    ## 다 썼으면 닫기\n",
        "    txt_label.close()"
      ],
      "metadata": {
        "id": "ff3cN_IQ_0DO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 하나만 꺼내봤더니 잘 됨 ##\n",
        "\n",
        "from glob import glob\n",
        "\n",
        "ttxt = glob('/content/ProjectVerCross/*.txt')[0]\n",
        "\n",
        "print(ttxt)\n",
        "with open(ttxt, 'r') as f :\n",
        "    lines = f.readlines()\n",
        "\n",
        "print(lines)"
      ],
      "metadata": {
        "id": "ti47oXRLDfdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_lst = []\n",
        "\n",
        "get_file = os.listdir(f'/content/dataset') ## 폴더 내의 파일들 리스트로 묶음\n",
        "for j in get_file :\n",
        "    if j.endswith('.png') : \n",
        "        img_lst.append(j)\n",
        "    if j.endswith('.jpg') : \n",
        "        img_lst.append(j)"
      ],
      "metadata": {
        "id": "cH9NRUmvEcE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil \n",
        "from tqdm import tqdm\n",
        "\n",
        "for img in tqdm(img_lst) : \n",
        "    shutil.move(f'/content/dataset/{img}', '/content/ProjectVerCross')"
      ],
      "metadata": {
        "id": "dotlDDJUEcE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('이미지 수 \\n',\n",
        "      len(glob('/content/ProjectVerCross/*.png')) + len(list(glob('/content/ProjectVerCross/*.jpg'))))\n",
        "print('txt로 변환한 라벨 수 \\n',\n",
        "      len(glob('/content/ProjectVerCross/*.txt')))\n",
        "\n",
        "print('총 파일 수 : {이전과 일치, 모든 파일 정상 변환 완료}\\n',\n",
        "      len(glob('/content/ProjectVerCross/*')))\n"
      ],
      "metadata": {
        "id": "HjXsbxVm_0DR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 여기서부터 합치기"
      ],
      "metadata": {
        "id": "o8qBfZ4TsLBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content\n",
        "# !unzip -qq \"/content/gdrive/MyDrive/data/yolo_texts.zip\" "
      ],
      "metadata": {
        "id": "SMGwe2SusKoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!unzip -qq \"/content/gdrive/MyDrive/Colab Notebooks/YOLO_V5/AugedBus.zip\" "
      ],
      "metadata": {
        "id": "ehb0B820swqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "\n",
        "os.mkdir('/content/MergedDataset')\n",
        "\n",
        "\n",
        "os.mkdir('/content/MergedDataset/train')\n",
        "os.mkdir('/content/MergedDataset/train/images')\n",
        "os.mkdir('/content/MergedDataset/train/labels')\n",
        "\n",
        "os.mkdir('/content/MergedDataset/valid')\n",
        "os.mkdir('/content/MergedDataset/valid/images')\n",
        "os.mkdir('/content/MergedDataset/valid/labels')"
      ],
      "metadata": {
        "id": "TkpHiCoFswlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "img_lst = []\n",
        "label_lst = []\n",
        "\n",
        "\n",
        "get_file = os.listdir(f'/content/ProjectVerCross') ## 폴더 내의 파일들 리스트로 묶음\n",
        "for j in get_file :\n",
        "    if j.endswith('.png') : \n",
        "        img_lst.append(j)\n",
        "    elif j.endswith('.jpg') : \n",
        "        img_lst.append(j)\n",
        "    elif j.endswith('.txt') :\n",
        "        label_lst.append(j)\n",
        "\n",
        "    elif j.endwith('.json') : \n",
        "        continue\n",
        "\n",
        "train_img , val_img = train_test_split(img_lst, test_size=0.1, random_state=42) ## train set과 validation set 분리\n",
        "\n",
        "train_lab = []\n",
        "val_lab = []\n",
        "\n",
        "for i in tqdm(label_lst) :\n",
        "    if i.split('.')[0] + '.jpg' in train_img :\n",
        "        train_lab.append(i)\n",
        "    elif i.split('.')[0] + '.png' in train_img :\n",
        "        train_lab.append(i)\n",
        "\n",
        "    elif i.split('.')[0] + '.jpg' in val_img :\n",
        "        val_lab.append(i)\n",
        "\n",
        "    elif i.split('.')[0] + '.png' in val_img :\n",
        "        val_lab.append(i)"
      ],
      "metadata": {
        "id": "7CepeT8uswjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Cross Train Image 수 : {len(train_img)}')\n",
        "print(f'Cross Train Label 수 : {len(train_lab)}')\n",
        "print(f'Cross Valid Image 수 : {len(val_img)}')\n",
        "print(f'Cross Valid Label 수 : {len(val_lab)}')"
      ],
      "metadata": {
        "id": "uucCF7m0swMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "for a, b in zip(train_img, train_lab) :\n",
        "    shutil.move(f'/content/ProjectVerCross/{a}', '/content/MergedDataset/train/images')\n",
        "    shutil.move(f'/content/ProjectVerCross/{b}', '/content/MergedDataset/train/labels')\n",
        "\n",
        "for c,d in zip(val_img, val_lab) : \n",
        "    shutil.move(f'/content/ProjectVerCross/{c}', '/content/MergedDataset/valid/images')\n",
        "    shutil.move(f'/content/ProjectVerCross/{d}', '/content/MergedDataset/valid/labels')"
      ],
      "metadata": {
        "id": "G84ZRTdq1TF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1차 확인"
      ],
      "metadata": {
        "id": "ZZ0kfslIzVmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = list(sorted(glob('/content/MergedDataset/train/images/*')))\n",
        "valid_path = list(sorted(glob('/content/MergedDataset/valid/images/*')))\n",
        "\n",
        "train_label_path = list(sorted(glob('/content/MergedDataset/train/labels/*')))\n",
        "valid_label_path = list(sorted(glob('/content/MergedDataset/valid/labels/*')))\n",
        "\n",
        "print(train_path[:10])\n",
        "print(train_label_path[:10])\n",
        "print('++++++++++')\n",
        "print(valid_path[:10])\n",
        "print(valid_label_path[:10])"
      ],
      "metadata": {
        "id": "7UZ1L1Wlxx_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "버스 옮겨줌"
      ],
      "metadata": {
        "id": "2oMcN1M9zYCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tr_img_path = list(sorted(glob('/content/train/images/*')))\n",
        "tr_lab_path = list(sorted(glob('/content/train/labels/*')))\n",
        "\n",
        "vl_img_path = list(sorted(glob('/content/valid/images/*')))\n",
        "vl_lab_path = list(sorted(glob('/content/valid/labels/*')))\n",
        "\n",
        "\n",
        "for tr_img, tr_lab in zip(tr_img_path, tr_lab_path ) :\n",
        "    shutil.move(tr_img, '/content/MergedDataset/train/images')\n",
        "    shutil.move(tr_lab, '/content/MergedDataset/train/labels')    \n",
        "\n",
        "for vl_img, vl_lab in zip(vl_img_path, vl_lab_path) :\n",
        "    shutil.move(vl_img, '/content/MergedDataset/valid/images')\n",
        "    shutil.move(vl_lab, '/content/MergedDataset/valid/labels')    "
      ],
      "metadata": {
        "id": "AygerTjwxx9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2차 확인\n",
        "잘 됨... 뿌듯.."
      ],
      "metadata": {
        "id": "zv9Nw-wr4AXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = list(sorted(glob('/content/MergedDataset/train/images/*')))\n",
        "valid_path = list(sorted(glob('/content/MergedDataset/valid/images/*')))\n",
        "\n",
        "train_label_path = list(sorted(glob('/content/MergedDataset/train/labels/*')))\n",
        "valid_label_path = list(sorted(glob('/content/MergedDataset/valid/labels/*')))\n",
        "\n",
        "print('Train 이미지 수 :',len(train_path))\n",
        "print('Train 라벨 수 :',len(train_label_path))\n",
        "print(train_path[:10])\n",
        "print(train_label_path[:10])\n",
        "print('++++++++++')\n",
        "print('Valid 이미지 수 :',len(valid_path))\n",
        "print('Valid 라벨 수 :',len(valid_label_path))\n",
        "print(valid_path[:10])\n",
        "print(valid_label_path[:10])\n",
        "\n"
      ],
      "metadata": {
        "id": "QBOOvb_rxx7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 경로 알리미 파일 만들어주기"
      ],
      "metadata": {
        "id": "5XqKg4r94LSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/MergedDataset/train.txt','w') as f :\n",
        "    f.write('\\n'.join(train_path) + '\\n')\n",
        "\n",
        "with open('/content/MergedDataset/valid.txt','w') as f :\n",
        "    f.write('\\n'.join(valid_path) + '\\n')"
      ],
      "metadata": {
        "id": "d36oJ0LYxx5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# yaml 파일 수정하기"
      ],
      "metadata": {
        "id": "AE7LBO8w4U4m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "아마 한 에폭에 속도가 20~30분이 안 걸린다면\n",
        "pathfile 경로를 txt가 아니라 폴더로 지정해서 그럼"
      ],
      "metadata": {
        "id": "pyBYjXY1G9HW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml"
      ],
      "metadata": {
        "id": "3VAXmCNi5y-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "train: ../train/images\n",
        "val: ../valid/images\n",
        "\n",
        "nc: 11\n",
        "names: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'bus']\n",
        "\n",
        "\n",
        "이렇게 되어있는 걸\n",
        "\n",
        "train: {YourTrainPathFile}\n",
        "val: {YourValidPathFile}\n",
        "\n",
        "nc: 14 \n",
        "names: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'bus', 'Zebra_Cross','G_Signal','R_Signal']\n",
        "\n",
        "이렇게 바꿀 거임\n",
        "\n",
        "'''\n",
        "\n",
        "YourTrainPathFile = '/content/MergedDataset/train/images'\n",
        "YourValidPathFile = '/content/MergedDataset/valid/images'\n",
        "\n",
        "with open('/content/MergedDataset/FinalYaml.yaml', 'w') as f:\n",
        "\n",
        "    f.close()\n",
        "\n",
        "with open('/content/MergedDataset/FinalYaml.yaml', 'r') as f:\n",
        "    data = yaml.load(f) \n",
        "\n",
        "## 학습 데이터, 검증 데이터 경로 지정\n",
        "dic = {\n",
        "'train' : f'{YourTrainPathFile}',\n",
        "'val' : f'{YourValidPathFile}',\n",
        "\n",
        "## 클래스 수\n",
        "'nc' : 14 ,\n",
        "\n",
        "## 종류\n",
        "'names' : ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'bus', 'Zebra_Cross','G_Signal','R_Signal']\n",
        "}\n",
        "\n",
        "with open('/content/MergedDataset/FinalYaml.yaml', 'w') as f :\n",
        "    yaml.dump(dic, f)\n"
      ],
      "metadata": {
        "id": "ymiuCSk5xx28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zip 묶기 (shutil에 좋은 함수가 있네요)"
      ],
      "metadata": {
        "id": "YU1E1addKgK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.make_archive('MergedDataset', 'zip', '/content/MergedDataset')"
      ],
      "metadata": {
        "id": "GCbEEC76xx0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "옮겨주기"
      ],
      "metadata": {
        "id": "hFLafAtNKkrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.move('/content/MergedDataset.zip','/content/gdrive/MyDrive/data')"
      ],
      "metadata": {
        "id": "KVoqQy95I3RM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}